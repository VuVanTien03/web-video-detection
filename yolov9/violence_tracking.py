import cv2
import torch
import numpy as np
from deep_sort_realtime.deepsort_tracker import DeepSort
from models.common import DetectMultiBackend, AutoShape

# Tham sá»‘
video_path = r"D:\Downloads\Gym Fight over a Cable Machine ğŸ¤” ğŸ’ªğŸ¼ Letâ€™s see who Wins ğŸ† #fighting #gym #fighter #shorts #viral.mp4"
conf_threshold = 0.3
device = "cuda" if torch.cuda.is_available() else "cpu"
weights_path = r"D:\code\python\DataMining\yolov9\owncode\data\weight.pt"
class_file = r"D:\code\python\DataMining\yolov9\owncode\data\classes.names"

# Khá»Ÿi táº¡o
tracker = DeepSort(max_age=5)
model = DetectMultiBackend(weights_path, device=device, fuse=True)
model = AutoShape(model)  # Äáº£m báº£o AutoShape bao bá»c mÃ´ hÃ¬nh

# Äá»c class names
with open(class_file, "r") as f:
    class_names = f.read().strip().split("\n")
colors = np.random.randint(0, 255, size=(len(class_names), 3))

# Má»Ÿ video
cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    print("KhÃ´ng thá»ƒ má»Ÿ video!")
    exit()

frame_count = 0
while cap.isOpened():
    ret, frame = cap.read()
    if not ret or frame is None:
        print(f"Frame {frame_count}: KhÃ´ng thá»ƒ Ä‘á»c frame tá»« video.")
        break

    frame_count += 1
    # Tiá»n xá»­ lÃ½ frame
    frame = cv2.resize(frame, (640, 640))  # KÃ­ch thÆ°á»›c vuÃ´ng
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Chuyá»ƒn sang RGB

    # Dá»± Ä‘oÃ¡n vá»›i AutoShape
    results = model(frame_rgb, size=640)  # Chá»‰ Ä‘á»‹nh kÃ­ch thÆ°á»›c Ä‘áº§u vÃ o rÃµ rÃ ng
    detections = results.pred[0]  # Láº¥y tensor dá»± Ä‘oÃ¡n tá»« results.pred

    if detections is None or len(detections) == 0:
        print(f"Frame {frame_count}: KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c váº­t thá»ƒ.")
        cv2.imshow("OT", frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break
        continue

    detect = []
    for det in detections:
        x1, y1, x2, y2, confidence, class_id = det[:6]
        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])  # Chuyá»ƒn sang int
        
        class_id = int(class_id)  # Äáº£m báº£o class_id lÃ  sá»‘ nguyÃªn
        print(f"Frame {frame_count}: {class_names[class_id]}, Conf: {confidence}")
        if confidence < conf_threshold:
            continue
        detect.append([[x1, y1, x2 - x1, y2 - y1], confidence, class_id])

    # Tracker
    tracks = tracker.update_tracks(detect, frame=frame)
    for track in tracks:
        if track.is_confirmed():
            track_id = track.track_id
            ltrb = track.to_ltrb()
            class_id = track.get_det_class()
            x1, y1, x2, y2 = map(int, ltrb)
            color = colors[class_id]
            B, G, R = map(int, color)
            label = f"{class_names[class_id]}-{track_id}"
            cv2.rectangle(frame, (x1, y1), (x2, y2), (B, G, R), 2)
            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

    cv2.imshow("OT", frame)
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()