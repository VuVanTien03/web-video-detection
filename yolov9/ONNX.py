import torch
import onnxruntime as ort 
import numpy as np
import cv2
import time 

# ƒê∆∞·ªùng d·∫´n m√¥ h√¨nh ONNX
weight_onnx = r"D:\code\python\DataMining\yolov9\owncode\data\weight.onnx"

session_options = ort.SessionOptions()
session_options.intra_op_num_threads = 4 
session_options.inter_op_num_threads = 4 
# Load ONNX model
session = ort.InferenceSession(weight_onnx, session_options = session_options , providers=['CPUExecutionProvider'])
# session.set_session_options(intra_op_num_threads=4, inter_op_num_threads=4)  # ƒêi·ªÅu ch·ªânh theo s·ªë l√µi CPU
input_name = session.get_inputs()[0].name

# H√†m ti·ªÅn x·ª≠ l√Ω ·∫£nh t·ª´ OpenCV frame
def pre_process_image_cv2(frame):
    # Resize v·ªÅ 640x640 v√† chuy·ªÉn BGR ‚Üí RGB
    image = cv2.resize(frame, (640, 640))
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Chuy·ªÉn sang [0,1] v√† transpose th√†nh (C, H, W)
    image = image.astype(np.float32) / 255.0
    image = np.transpose(image, (2, 0, 1))  # (3, 640, 640)
    image = np.expand_dims(image, axis=0)   # (1, 3, 640, 640)
    return image

# Ch·∫°y video + ƒëo th·ªùi gian x·ª≠ l√Ω
def excute_time(file_path):
    cap = cv2.VideoCapture(file_path)
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        start = time.time()

        input = pre_process_image_cv2(frame)
        outputs = session.run(None, {input_name: input})

        end = time.time()
        print(f"‚è±Ô∏è Time per frame: {end - start:.3f}s")

        # (Tu·ª≥ b·∫°n) x·ª≠ l√Ω output: v·∫Ω box, decode k·∫øt qu·∫£ ·ªü ƒë√¢y

    cap.release()
    print("‚úÖ Done")

if __name__ == "__main__":
    video_path = r"D:\Downloads\10 Fastest Finishes in UFC History üèÜ.mp4"
    excute_time(video_path)
